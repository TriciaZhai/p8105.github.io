<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Simulation</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/latest/css/font-awesome.min.css" />
<script defer src="https://use.fontawesome.com/releases/v5.0.3/js/all.js"></script>
<script defer src="https://use.fontawesome.com/releases/v5.0.0/js/v4-shims.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">P8105</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="schedule.html">Schedule</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="topic_what_is_data_science.html">What is Data Science?</a>
    </li>
    <li>
      <a href="topic_building_blocks.html">Building Blocks</a>
    </li>
    <li>
      <a href="topic_data_wrangling_i.html">Data Wrangling I</a>
    </li>
    <li>
      <a href="topic_visualization_and_eda.html">Visualization and EDA</a>
    </li>
    <li>
      <a href="topic_data_wrangling_ii.html">Data Wrangling II</a>
    </li>
    <li>
      <a href="topic_interactivity.html">Interactivity</a>
    </li>
    <li>
      <a href="topic_iteration.html">Iteration</a>
    </li>
    <li>
      <a href="topic_linear_models.html">Linear Models</a>
    </li>
    <li>
      <a href="topic_other_material.html">Other Materials</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Datasets
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="dataset_airbnb.html">Airbnb</a>
    </li>
    <li>
      <a href="dataset_brfss.html">BRFSS</a>
    </li>
    <li>
      <a href="dataset_fivethirtyeight.html">FiveThirtyEight</a>
    </li>
    <li>
      <a href="dataset_instacart.html">Instacart</a>
    </li>
    <li>
      <a href="dataset_mr_trash_wheel.html">Mr. Trash Wheel</a>
    </li>
    <li>
      <a href="dataset_noaa.html">NOAA</a>
    </li>
    <li>
      <a href="dataset_restaurant_inspections.html">NYC Restaurant Inspections</a>
    </li>
  </ul>
</li>
<li>
  <a href="homework_and_projects.html">Homework and Projects</a>
</li>
<li>
  <a href="course_communication.html">Communication</a>
</li>
<li>
  <a href="https://github.com/P8105/p8105.github.io">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Simulation</h1>

</div>


<p>We’ve noted that functions are helpful when you repeat code more than twice; we’ve also noted that a lot of statistical methods involve doing the same thing a large number of times. Simulation is a common statistical approach that takes advantage of the ability to iterate many times using computers.</p>
<p>This is the third module in the <a href="topic_iteration.html">Iteration</a> topic; the relevant slack channel is <a href="https://p8105-fall2018.slack.com/messages/CCAAE7XDW">here</a>.</p>
<div id="some-slides" class="section level2">
<h2>Some slides</h2>
<script async class="speakerdeck-embed" data-id="285289b17d194a4282d53f1800d37199" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"></script>
<div style="margin-bottom:5px">
<strong> <a href="https://speakerdeck.com/jeffgoldsmith/p8105-simulation-and-bootstrapping" title="Simulation and Bootstrapping" target="_blank">Simulation and Bootstrapping</a> </strong> from <strong><a href="https://speakerdeck.com/jeffgoldsmith" target="_blank">Jeff Goldsmith</a></strong>.
</div>
<p><br></p>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<p>I’ll write code for today’s content in a new R Markdown document called <code>listcols_and_bootstrapping.Rmd</code> in the <code>example_iteration</code> directory / repo. The code chunk below loads the usual packages.</p>
<pre class="r"><code>library(tidyverse)

theme_set(theme_bw())
theme_update(legend.position = &quot;bottom&quot;)

set.seed(1)</code></pre>
<p>Things are gonna get a little weird…</p>
<div id="simulation-slr-for-one-n" class="section level3">
<h3>Simulation: SLR for one <span class="math inline">\(n\)</span></h3>
<p>Last class we wrote a short function to simulate data from a simple linear regression, fit the regression model, and return estimates of regression coefficients. Specifically, we generate data from <span class="math display">\[ y_i = \beta_0 + \beta_1 x_i + \epsilon_i \]</span> for subjects <span class="math inline">\(1 \leq i \leq n\)</span> with <span class="math inline">\(\epsilon_i \sim N[0,1]\)</span> and return estimates <span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1\)</span>. That function is below.</p>
<pre class="r"><code>sim_regression = function(n, beta0 = 2, beta1 = 3) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 1, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, 1)
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta0_hat = coef(ls_fit)[1],
    beta1_hat = coef(ls_fit)[2]
  )
}</code></pre>
<p>Important statistical properties of estimates <span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1\)</span> are established under the conceptual framework of repeated sampling. If you could draw from a population over and over, your estimates will have a known mean and variance: <span class="math display">\[ \hat{\beta}_0 \sim \left[\beta_0, \sigma^2 \left(\frac{1}{n} + \frac{\bar{x}}{\sum (x_i - \bar{x})^2}\right) \right] \mbox{ and } \hat{\beta}_1 \sim \left[\beta_1,\frac{\sigma^2}{\sum (x_i - \bar{x})^2} \right] \]</span> (Because our simulation design generates errors from a Normal distribution we also know that the estimates follow a Normal distribution, although that’s not guaranteed by least squares estimation.)</p>
<p>In the real world, drawing samples is time consuming and costly, so “repeated sampling” remains conceptual. On a computer, though, drawing samples is pretty easy. That makes simulation an appealing way to examine the statistical properties of your estimators.</p>
<p>Let’s run <code>sim_regression()</code> 100 times to see the effect of randomness in <span class="math inline">\(\epsilon\)</span> on estimates <span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1\)</span>.</p>
<pre class="r"><code>output = vector(&quot;list&quot;, 100)

for (i in 1:100) {
  output[[i]] = sim_regression(30)
}

sim_results = bind_rows(output)</code></pre>
<p>Taking a look at the <code>for</code> loop we used to create these results, you might notice that there’s no <code>input</code> list – the sequence is used to keep track of the output but doesn’t affect the computation performed inside the <code>for</code> loop. In cases like these, the <code>purrr::rerun</code> function is very handy.</p>
<pre class="r"><code>sim_results = 
  rerun(100, sim_regression(30, 2, 3)) %&gt;% 
  bind_rows()</code></pre>
<p>Structurally, <code>rerun</code> is a lot like <code>map</code> – the first argument defines the amount of iteration and the second argument is the function to use in each iteration step. As with <code>map</code>, we’ve replaced a for loop with a segment of code that makes our purpose much more transparent but both approaches give the same results.</p>
<p>Let’s make some quick plots and compute some summaries for our simulation results.</p>
<pre class="r"><code>sim_results %&gt;% 
  ggplot(aes(x = beta0_hat, y = beta1_hat)) + 
  geom_point()</code></pre>
<p><img src="simulation_files/figure-html/unnamed-chunk-4-1.png" width="90%" /></p>
<pre class="r"><code>
sim_results %&gt;% 
  gather(key = parameter, value = estimate, beta0_hat:beta1_hat) %&gt;% 
  group_by(parameter) %&gt;% 
  summarize(emp_mean = mean(estimate),
            emp_var = var(estimate)) %&gt;% 
  knitr::kable(digits = 3)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">parameter</th>
<th align="right">emp_mean</th>
<th align="right">emp_var</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">beta0_hat</td>
<td align="right">1.995</td>
<td align="right">0.081</td>
</tr>
<tr class="even">
<td align="left">beta1_hat</td>
<td align="right">3.021</td>
<td align="right">0.056</td>
</tr>
</tbody>
</table>
<p>This is <strong><em>great</em></strong>! We’ve seen how our estimates are distributed under our simulation scenario, and can compare empirical results to theoretical ones. In this way, we can build intution for fundamental statistical procedures under repeated sampling in a way that’s not possible with single data sets.</p>
</div>
<div id="simulation-slr-for-several-ns" class="section level3">
<h3>Simulation: SLR for several <span class="math inline">\(n\)</span>s</h3>
<p>Sample size makes a huge difference on the variance of estimates in SLR (and pretty much every statistical method). Let’s try to clarify that effect through simulating at a few sample sizes.</p>
<p>I’ll start this process with a for loop around the code I established above using <code>rerun</code> (I could start from scratch by nesting one for loop in another for loop, but let’s not).</p>
<pre class="r"><code>n_list = list(&quot;n_30&quot;  = 30, 
              &quot;n_60&quot;  = 60, 
              &quot;n_120&quot; = 120, 
              &quot;n_240&quot; = 240)
output = vector(&quot;list&quot;, length = 4)

for (i in 1:4) {
  output[[i]] = rerun(100, sim_regression(n_list[[i]])) %&gt;% 
    bind_rows
}</code></pre>
<p>After this loop, <code>output</code> is a list of 4 data frames; each data frame contains the results of 100 simulations at different sample sizes.</p>
<p>Before we spend time looking at the results of the simulation, let’s recast this using <code>map</code>. I want to use a single function in my call to <code>map_df</code>, so I’m going to write a wrapper for the call to <code>rerun</code> that allows me to change the parameters of the simulation (i.e. the argument to <code>sim_regression</code>) and the number of simulation replicates (i.e. the first argument to <code>rerun</code>). Once I have this, I’ll call <code>map_df</code> to perform the complete simulation.</p>
<pre class="r"><code>simulate_n_regressions = function(n_runs = 100, n, beta0 = 2, beta1 = 3) {
  
  rerun(n_runs, sim_regression(n, beta0, beta1)) %&gt;% 
    bind_rows()
  
}

sim_results = 
  map_df(.x = n_list, ~ simulate_n_regressions(n = .x), .id = &quot;sample_size&quot;) </code></pre>
<p>Using a different call, I could increase the number of simulation runs or vary the parameters in the regression model:</p>
<pre class="r"><code>sim_results = 
  map_df(.x = n_list, ~ simulate_n_regressions(n = .x, n_runs = 1000, beta0 = 2, beta1 = 3),
         .id = &quot;sample_size&quot;) </code></pre>
<p>Let’s take a look at what we’ve accomplished in our simulations! First I’ll take a look at the distribution of slope estimates across sample sizes.</p>
<pre class="r"><code>sim_results %&gt;% 
  mutate(sample_size = fct_inorder(sample_size)) %&gt;% 
  ggplot(aes(x = sample_size, y = beta1_hat, fill = sample_size)) + 
  geom_violin()</code></pre>
<p><img src="simulation_files/figure-html/unnamed-chunk-8-1.png" width="90%" /></p>
<p>These estimates are centered around the truth (3) for each sample size, and the width of the distribution shrinks as sample size grows.</p>
<p>Next, I’ll look at the bivariate distribution of intercept and slope estimates across sample sizes.</p>
<pre class="r"><code>sim_results %&gt;% 
  mutate(sample_size = fct_inorder(sample_size)) %&gt;% 
  ggplot(aes(x = beta0_hat, y = beta1_hat)) + 
  geom_point(alpha = .2) + 
  facet_grid(~sample_size)</code></pre>
<p><img src="simulation_files/figure-html/unnamed-chunk-9-1.png" width="90%" /></p>
<p>The variability in the slope estimates was shown in the violin plot, but now we have a sense for the bivariate distribution of intercepts and slopes. Estimates of the intercept and slope are correlated with each other; this is expected from theoretical results describing the joint distribution of estimated regression coefficients.</p>
<p>Lastly I’ll look at the empirical mean and variance of these estimates.</p>
<pre class="r"><code>sim_results %&gt;% 
  gather(key = parameter, value = estimate, beta0_hat:beta1_hat) %&gt;% 
  group_by(parameter, sample_size) %&gt;% 
  summarize(emp_mean = mean(estimate),
            emp_var = var(estimate)) %&gt;% 
  knitr::kable(digits = 3)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">parameter</th>
<th align="left">sample_size</th>
<th align="right">emp_mean</th>
<th align="right">emp_var</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">beta0_hat</td>
<td align="left">n_120</td>
<td align="right">2.003</td>
<td align="right">0.017</td>
</tr>
<tr class="even">
<td align="left">beta0_hat</td>
<td align="left">n_240</td>
<td align="right">1.996</td>
<td align="right">0.008</td>
</tr>
<tr class="odd">
<td align="left">beta0_hat</td>
<td align="left">n_30</td>
<td align="right">1.998</td>
<td align="right">0.073</td>
</tr>
<tr class="even">
<td align="left">beta0_hat</td>
<td align="left">n_60</td>
<td align="right">2.000</td>
<td align="right">0.037</td>
</tr>
<tr class="odd">
<td align="left">beta1_hat</td>
<td align="left">n_120</td>
<td align="right">2.997</td>
<td align="right">0.008</td>
</tr>
<tr class="even">
<td align="left">beta1_hat</td>
<td align="left">n_240</td>
<td align="right">3.003</td>
<td align="right">0.004</td>
</tr>
<tr class="odd">
<td align="left">beta1_hat</td>
<td align="left">n_30</td>
<td align="right">3.003</td>
<td align="right">0.036</td>
</tr>
<tr class="even">
<td align="left">beta1_hat</td>
<td align="left">n_60</td>
<td align="right">3.000</td>
<td align="right">0.019</td>
</tr>
</tbody>
</table>
<p>These values are consistent with the formulas presented above. This kind of check is a useful way to support derivations (although they don’t serve as a formal proof in any way).</p>
</div>
<div id="bootstrapping" class="section level3">
<h3>Bootstrapping</h3>
<p>Bootstrapping is based on the idea of repeated sampling which underlies most approaches to statistical inference. Traditionally, the distribution of a sample statistic (sample mean, SLR coefficients, etc.) for repeated, random draws from a population has been established theoretically. These theoretical distributions make some assumptions about the underlying population from which samples are drawn, or depend on large sample sizes for asymptotic results.</p>
<p>In cases where the assumptions aren’t met, or sample sizes aren’t large enough for asymptotics to kick in, it is still necessary to make inferences using the sample statistic. In these cases, drawing repeatedly from the original population would be great – one could simple draw a lot of samples and look at the empirical (rather than theoretical) distribution. But, as we said in <a href="iteration_and_simulation.html">iteration and simulation</a>, repeated sampling just doesn’t happen in the real world.</p>
<p>Repeated sampling <em>can</em> happen on a computer though. To bootstrap, one draws repeated samples (with the same sample size) from the original sample <strong><em>with replacement</em></strong> to mimic the process of drawing repeated samples from the population. The bootstrap samples will differ from the original sample, and the sample statistic of interest (sample mean, SLR coefficients, etc.) can be computed for each bootstrap sample. Looking at the distribution of the statistic across samples gives a sense of the uncertainty in the estimate.</p>
</div>
<div id="bootstrapping-in-slr" class="section level3">
<h3>Bootstrapping in SLR</h3>
<p>Let’s look at a couple of simulated data sets. Both are generated from a simple linear regression, but they have different error distributions.</p>
<pre class="r"><code>set.seed(10)

n_samp = 250

sim_df_const = tibble(
  x = rnorm(n_samp, 1, 1),
  error = rnorm(n_samp, 0, 1),
  y = 2 + 3 * x + error
)

sim_df_nonconst = sim_df_const %&gt;% 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)

bind_rows(
  mutate(sim_df_const, data = &quot;sim_df_const&quot;),
  mutate(sim_df_nonconst, data = &quot;sim_df_nonconst&quot;)
) %&gt;% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = &quot;lm&quot;) +
  facet_grid(~data) </code></pre>
<p><img src="simulation_files/figure-html/unnamed-chunk-11-1.png" width="90%" /></p>
<p>These datasets have roughly the same overall variance, but the left panel shows data with constant variance and the right panel shows data with non-constant variance. For this reason, ordinary least squares should provide reasonable estimates in both cases, but inference is standard inference approaches may only be justified for the data on the left.</p>
<p>The output below shows results from fitting simple linear regressions to both datasets.</p>
<pre class="r"><code>lm(y ~ x, data = sim_df_const) %&gt;% summary()
## 
## Call:
## lm(formula = y ~ x, data = sim_df_const)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -3.00497 -0.75408 -0.05951  0.80840  2.54356 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.96777    0.09435   20.86   &lt;2e-16 ***
## x            3.11086    0.07193   43.24   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.075 on 248 degrees of freedom
## Multiple R-squared:  0.8829, Adjusted R-squared:  0.8824 
## F-statistic:  1870 on 1 and 248 DF,  p-value: &lt; 2.2e-16
lm(y ~ x, data = sim_df_nonconst) %&gt;% summary()
## 
## Call:
## lm(formula = y ~ x, data = sim_df_nonconst)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.7759 -0.4854 -0.0520  0.4214  3.3971 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.03488    0.09267   21.96   &lt;2e-16 ***
## x            3.09472    0.07066   43.80   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.056 on 248 degrees of freedom
## Multiple R-squared:  0.8855, Adjusted R-squared:  0.8851 
## F-statistic:  1918 on 1 and 248 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Despite the very different error structures, standard errors for coefficient estimates are similar in both cases!</p>
<p>We’ll use the bootstrap to make inference for the data on the right. This is intended largely as an illustration for how to use the bootstrap in cases where the theoretical distribution is “unknown”, although for these data in particular weighted least squares is more appropriate.</p>
</div>
<div id="drawing-one-bootstrap-sample" class="section level3">
<h3>Drawing one bootstrap sample</h3>
<p>Let’s write a quick function to generate our bootstrap samples. This function should have the data frame as the argument, and should return a sample from that dataframe drawn with replacement.</p>
<pre class="r"><code>boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}</code></pre>
<p>We should also do a quick check to see if this is working.</p>
<pre class="r"><code>boot_sample(sim_df_nonconst)
## # A tibble: 250 x 3
##         x   error     y
##     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1  1.33   -1.52    4.47
## 2  0.691   0.637   4.71
## 3  0.170   0.305   2.81
## 4 -0.0626  0.0265  1.84
## 5 -0.963  -0.248  -1.14
## 6  1.71   -2.57    4.57
## # ... with 244 more rows</code></pre>
<p>That looks about right.</p>
</div>
<div id="drawing-many-bootstrap-samples" class="section level3">
<h3>Drawing many bootstrap samples</h3>
<p>We’re going to draw repeated samples with replacement, and then analyze each of those samples separately. It would be really great to have a data structure that makes it possible to keep track of everything. Maybe a <strong><em>list column</em></strong>??!</p>
<p>Let’s give that a try:</p>
<pre class="r"><code>boot_straps = data_frame(
  strap_number = 1:1000,
  strap_sample = rerun(1000, boot_sample(sim_df_nonconst))
)

boot_straps
## # A tibble: 1,000 x 2
##   strap_number strap_sample      
##          &lt;int&gt; &lt;list&gt;            
## 1            1 &lt;tibble [250 × 3]&gt;
## 2            2 &lt;tibble [250 × 3]&gt;
## 3            3 &lt;tibble [250 × 3]&gt;
## 4            4 &lt;tibble [250 × 3]&gt;
## 5            5 &lt;tibble [250 × 3]&gt;
## 6            6 &lt;tibble [250 × 3]&gt;
## # ... with 994 more rows</code></pre>
<p>We can do a few of quick checks to make sure this has worked as intended. First we’ll look at a couple of bootstrap samples.</p>
<pre class="r"><code>boot_straps %&gt;% 
  filter(strap_number %in% 1:2) %&gt;% 
  mutate(strap_sample = map(strap_sample, ~arrange(.x, x))) %&gt;% 
  pull(strap_sample)
## [[1]]
## # A tibble: 250 x 3
##        x  error      y
##    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 -1.12  -0.187 -1.54 
## 2 -1.12  -0.187 -1.54 
## 3 -0.759  0.146 -0.131
## 4 -0.675  0.324  0.298
## 5 -0.675  0.324  0.298
## 6 -0.658 -0.509 -0.483
## # ... with 244 more rows
## 
## [[2]]
## # A tibble: 250 x 3
##        x  error       y
##    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 -1.32   1.94  -0.0246
## 2 -0.854 -0.210 -0.771 
## 3 -0.854 -0.210 -0.771 
## 4 -0.759  0.146 -0.131 
## 5 -0.658 -0.509 -0.483 
## 6 -0.627  0.514  0.634 
## # ... with 244 more rows</code></pre>
<p>Seems okay – some values are repeated, some don’t appear in both datasets. Next I’ll use ggplot to show some of these datasets, and to include a linear fit for each.</p>
<pre class="r"><code>boot_straps %&gt;% 
  filter(strap_number %in% 1:3) %&gt;% 
  unnest() %&gt;% 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = &quot;lm&quot;, se = FALSE) +
  facet_grid(~strap_number) </code></pre>
<p><img src="simulation_files/figure-html/unnamed-chunk-17-1.png" width="90%" /></p>
<p>This shows some of the differences across bootstrap samples, and shows that the fitted regression lines aren’t the same for every bootstrap sample.</p>
</div>
<div id="analyzing-bootstrap-samples" class="section level3">
<h3>Analyzing bootstrap samples</h3>
<p>My goal, of course, isn’t to analyze bootstrap samples by plotting them – I’d like to get a sense of the variability in estimated intercepts and slopes across all my bootstrap samples.</p>
<p>To do that, I’ll use the analytic pipeline we established above: fit the model; tidy the output; unnest and examine the results. The code chunk below uses this pipeline to look at bootstrap standard errors for the estimated regression coefficients.</p>
<pre class="r"><code>bootstrap_results = 
  boot_straps %&gt;% 
  mutate(models = map(strap_sample, ~lm(y ~ x, data = .x) ),
         results = map(models, broom::tidy)) %&gt;% 
  select(-strap_sample, -models) %&gt;% 
  unnest() %&gt;% 
  group_by(term) %&gt;% 
  summarize(boot_se = sd(estimate))

bootstrap_results
## # A tibble: 2 x 2
##   term        boot_se
##   &lt;chr&gt;         &lt;dbl&gt;
## 1 (Intercept)  0.0524
## 2 x            0.0822</code></pre>
<p>Comparing these to the results of ordinary least squares, we see that the standard error for the intercept is much smaller and the standard error for the intercept is a bit larger. This is reasonable, given the non-constant variance in the data given smaller residuals around zero and larger residuals in the the tails of the <code>x</code> distribution.</p>
<p>In this case, we can expand the three-panel plot we showed previously to visualize the results of our bootstrap process.</p>
<pre class="r"><code>boot_straps %&gt;% 
  unnest() %&gt;% 
  ggplot(aes(x = x, y = y)) + 
  geom_line(aes(group = strap_number), stat = &quot;smooth&quot;, method = &quot;lm&quot;, se = FALSE, alpha = .1, color = &quot;blue&quot;) +
  geom_point(data = sim_df_nonconst, alpha = .5)</code></pre>
<p><img src="simulation_files/figure-html/unnamed-chunk-19-1.png" width="90%" /></p>
<p>In comparison to the standard error bands in our previous plot (which are based on OLS), the distribution of regression lines is narrower near <span class="math inline">\(x = 0\)</span> and wider at the ends of the <span class="math inline">\(x\)</span> distribution.</p>
</div>
<div id="bootstrap" class="section level3">
<h3><code>bootstrap</code></h3>
<p>Bootstrapping is common enough that it’s been automated, to some degree, in the <code>modelr::boostrap</code> function. This function makes it easy to draw bootstrap samples, and stores them in a mostly-helpful way – as a <code>resample</code> object that can be converted to and treated like a data frame.</p>
<pre class="r"><code>library(modelr)

boot_straps = 
  sim_df_nonconst %&gt;% 
  bootstrap(n = 1000)

boot_straps$strap[[1]]
## &lt;resample [250 x 3]&gt; 77, 192, 117, 181, 71, 156, 25, 164, 5, 190, ...
as_data_frame(boot_straps$strap[[1]])
## # A tibble: 250 x 3
##        x   error       y
##    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
## 1 -0.480  0.0834  0.644 
## 2  2.00  -1.14    6.85  
## 3  2.04   1.27    9.39  
## 4  1.43  -0.132   6.14  
## 5  1.38   1.09    7.24  
## 6 -1.32   1.94   -0.0246
## # ... with 244 more rows</code></pre>
<p>Let’s repeat our analysis pipeline using the <code>bootstrap</code> function instead of our own process for drawing samples with replacement.</p>
<pre class="r"><code>sim_df_nonconst %&gt;% 
  bootstrap(n = 1000) %&gt;% 
  mutate(models = map(strap, ~lm(y ~ x, data = .x) ),
         results = map(models, broom::tidy)) %&gt;% 
  select(-strap, -models) %&gt;% 
  unnest() %&gt;% 
  group_by(term) %&gt;% 
  summarize(boot_se = sd(estimate))
## # A tibble: 2 x 2
##   term        boot_se
##   &lt;chr&gt;         &lt;dbl&gt;
## 1 (Intercept)  0.0545
## 2 x            0.0821</code></pre>
<p>The results are the same (up to resampling variability), and the code to get here is pretty clean.</p>
<p>Also, check this out – to bootstrap the dataset with constant error variance, we only have to change the input dataframe!</p>
<pre class="r"><code>sim_df_const %&gt;% 
  bootstrap(n = 1000) %&gt;% 
  mutate(models = map(strap, ~lm(y ~ x, data = .x) ),
         results = map(models, broom::tidy)) %&gt;% 
  select(-strap, -models) %&gt;% 
  unnest() %&gt;% 
  group_by(term) %&gt;% 
  summarize(boot_se = sd(estimate))
## # A tibble: 2 x 2
##   term        boot_se
##   &lt;chr&gt;         &lt;dbl&gt;
## 1 (Intercept)  0.0871
## 2 x            0.0652</code></pre>
<p>These results generally agree with the output of the OLS procedure, which is nice.</p>
</div>
</div>
<div id="other-materials" class="section level2">
<h2>Other materials</h2>
<p>List columns take some getting used to; there are some materials to help with that.</p>
<ul>
<li>R for Data Science has a chapter on <a href="http://r4ds.had.co.nz/many-models.html">fitting many models</a></li>
<li>Jenny Bryan’s <a href="https://jennybc.github.io/purrr-tutorial/">purrr tutorial</a> has useful list-column examples</li>
</ul>
<p>Boostrapping and resampling are also new concepts; the materials below explore these using tidyverse approaches.</p>
<ul>
<li>The <a href="https://github.com/tidyverse/modelr"><code>modelr</code> package</a> has a page</li>
<li>The bootsrapping <a href="https://cran.r-project.org/web/packages/broom/vignettes/bootstrapping.html">vignette</a> uses a framework similar to the one we used</li>
<li>We didn’t discuss cross validation, another popular approach, ut you can read up on it <a href="https://drsimonj.svbtle.com/k-fold-cross-validation-with-modelr-and-broom">here</a> and <a href="http://rpubs.com/dgrtwo/cv-modelr">here</a></li>
</ul>
<p>The code that I produced working examples in lecture is <a href="https://github.com/p8105/iteration">here</a>.</p>
</div>

<br><br>
<footer>
  <img src="images/p8105_stickers.png" alt="stickers" style="width:30%">
  <br>
  <p class="copyright text-muted" align="center">Copyright &copy; 2018 Jeff Goldsmith</p>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
