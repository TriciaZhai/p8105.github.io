---
title: "Cross Validation"
output:
  html_document: 
    toc: true
    toc_float: true
---

Although hypothesis tests provide a way to compare nested linear models, in many situations the approaches under consideration don't fit nicely in this paradigm. Indeed, for many modern tools and in many applications, the emphasis lies on prediction accuracy rather than on statistical significance. In these cases, cross validation provides a way to compare the predictive performance of competing methods.

This is the second module in the [Linear Models](topic_iteration.html) topic; the relevant slack channel is [here](https://p8105-fall2018.slack.com/messages/CCAAE9AAU).

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

library(tidyverse)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```

## Some slides

<script async class="speakerdeck-embed" data-id="285289b17d194a4282d53f1800d37199" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>
<div style="margin-bottom:5px"> <strong> <a href="https://speakerdeck.com/jeffgoldsmith/p8105-cross-validation" title="Cross validation" target="_blank">Cross validation</a> </strong> from <strong><a href="https://speakerdeck.com/jeffgoldsmith" target="_blank">Jeff Goldsmith</a></strong>. </div><br>


## Example

I'll write code for today's content in a new R Markdown document called `simulation.Rmd` in the `iteration` directory / repo. The code chunk below loads the usual packages and sets a seed for reproducibility.

```{r}
library(tidyverse)
library(modelr)
library(mgcv)

set.seed(1)
```



### CV by hand

```{r}
nonlin_df = tibble(
  id = 1:100,
  x = runif(100, 0, 1),
  y = 1 - 10 * (x - .3) ^ 2 + rnorm(100, 0, .3)
)

ggplot(nonlin_df, aes(x = x, y = y)) + geom_point() + theme_bw()
```


```{r}
train_df = sample_n(nonlin_df, 80)
test_df = anti_join(nonlin_df, train_df, by = "id")
```


```{r}
lin_mod = lm(y ~ x, data = train_df)
nonlin_mod = mgcv::gam(y ~ s(x), data = train_df)
wiggly_mod = mgcv::gam(y ~ s(x, k = 30), sp = 10e-6, data = train_df)
```

gam is weird, let's see some fits

```{r}
train_df %>% 
  add_predictions(nonlin_mod) %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + 
  geom_line(aes(y = pred), color = "red")

train_df %>% 
  add_predictions(wiggly_mod) %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + 
  geom_line(aes(y = pred), color = "red")
```

```{r}
rmse(lin_mod, test_df)
rmse(nonlin_mod, test_df)
rmse(wiggly_mod, test_df)
```



### CV using `modelr`

```{r}
cv_df = 
  crossv_mc(nonlin_df, 100) 

cv_df %>% pull(train) %>% .[[1]] %>% as_tibble
cv_df %>% pull(test) %>% .[[1]] %>% as_tibble
```

```{r}
cv_df =
  cv_df %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))
```



```{r}
cv_df = 
  cv_df %>% 
  mutate(lin_mod = map(train, ~lm(y ~ x, data = .x)),
         nonlin_mod = map(train, ~mgcv::gam(y ~ s(x), data = .x)),
         wiggly_mod = map(train, ~gam(y ~ s(x, k = 30), sp = 10e-6, data = .x))) %>% 
  mutate(rmse_lin    = map2_dbl(lin_mod, test, ~rmse(model = .x, data = .y)),
         rmse_nonlin = map2_dbl(nonlin_mod, test, ~rmse(model = .x, data = .y)),
         rmse_wiggly = map2_dbl(wiggly_mod, test, ~rmse(model = .x, data = .y)))
```


```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

### Nepalese children

```{r}
child_growth = read_csv("./data/nepalese_children.csv")
```

```{r}
child_growth %>% 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = .5)
```


```{r}
child_growth =
  child_growth %>% 
  mutate(weight_sp = (weight > 7) * (weight - 7))
```


```{r}
lin_mod = lm(armc ~ weight, data = child_growth)
pwl_mod = lm(armc ~ weight + weight_sp, data = child_growth)
nonlin_mod = gam(armc ~ s(weight), data = child_growth)
```


```{r}
child_growth %>% 
  gather_predictions(lin_mod, pwl_mod, nonlin_mod) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red") + 
  facet_grid(~model)
```



```{r}
cv_df =
  crossv_mc(child_growth, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))
```


```{r}
cv_df = 
  cv_df %>% 
  mutate(lin_mod = map(train, ~lm(armc ~ weight, data = .x)),
         pwl_mod = map(train, ~lm(armc ~ weight + weight_sp, data = .x)),
         nonlin_mod = map(train, ~gam(armc ~ s(weight), data = as_tibble(.x)))) %>% 
  mutate(rmse_lin    = map2_dbl(lin_mod, test, ~rmse(model = .x, data = .y)),
         rmse_pwl = map2_dbl(pwl_mod, test, ~rmse(model = .x, data = .y)),
         rmse_nonlin = map2_dbl(nonlin_mod, test, ~rmse(model = .x, data = .y)))
```


```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```


### real example


```{r, eval=FALSE}


## penalized spline
fx = gam(armc ~ s(weight), data = data.train)
plot.fx = data.frame(weight = data.train$weight, fx = fitted(fx))
p1 + geom_line(data = plot.fx, aes(x = weight, y = fx, color = NULL), color = "blue", size = 1.5)

CV[5] = mean((data.valid$armc - predict(fx, newdata = data.valid))^2)


## kernel smoother
plot.fx = with(data.train, as.data.frame(ksmooth(weight, armc, kernel = "normal", bandwidth = 2)))
p1 + geom_line(data = plot.fx, aes(x = x, y = y, color = NULL), color = "blue", size = 1.5)

fx.cv = with(data.train, ksmooth(weight, armc, kernel = "normal", bandwidth = 2, x.points = data.valid$weight)$y)
CV[6] = mean((data.valid$armc[order(data.valid$weight)] - fx.cv)^2)


## compare CV
CV = data.frame(x = 1:6, CV = CV)
ggplot(CV, aes(x = x, y = CV)) + geom_point() + geom_line() + labs(x = "") + 
  scale_x_continuous(breaks = 1:6, labels = c("Obs Mean", "SLR", "Poly", "Spline", "P-Spline", "Kernel")) + 
  theme_bw()


####################################################################
## extended case study of arm circumference
####################################################################

## penalized spline
fx = gam(armc ~ s(weight), data = data.train)
plot.fx = data.frame(weight = data.train$weight, fx = fitted(fx))
p1 + geom_line(data = plot.fx, aes(x = weight, y = fx, color = NULL), color = "blue", size = 1.5)
summary(fx)

## penalized spline -- different penalty and spline basis
fx = gam(armc ~ s(weight, k = 100), data = data.train, sp = (.0001))
plot.fx = data.frame(weight = data.train$weight, fx = fitted(fx))
p1 + geom_line(data = plot.fx, aes(x = weight, y = fx, color = NULL), color = "blue", size = 1.5)
summary(fx)


## separate boys and girls
ggplot(data.train, aes(x = weight, y = armc, color = as.factor(sex))) + geom_point(alpha = .2) +
  scale_color_manual(values = c("blue", "red"), guide = FALSE) +
  stat_smooth(method = "gam", formula = y ~ s(x), se = FALSE, size = 1.5) + 
  theme_bw()

fx = gam(armc ~ sex + sex * weight + s(weight), data = data.train) 
summary(fx)
summary(lm(armc ~ sex + sex * weight, data = data.train))

plot(fx)

## separate age groups
data.train = mutate(data.train, ageGroup = cut(age, breaks = c(0, 22, 32, 40, 50, 100), labels = 1:5))
data.valid = mutate(data.valid, ageGroup = cut(age, breaks = c(0, 22, 32, 40, 50, 100), labels = 1:5))

ggplot(data.train, aes(x = weight, y = armc, color = ageGroup)) + geom_point(alpha = .2) +
  stat_smooth(method = "gam", formula = y ~ s(x), se = FALSE, size = 1.5) + 
  scale_color_discrete(guide = FALSE) + 
  theme_bw()

## smooth effects of age and weight
fx = gam(armc ~ s(age) + s(weight), data = data.train) 
summary(fx)

CV[7,] = c(7, mean((data.valid$armc - predict(fx, newdata = data.valid))^2))

par(mfrow = c(1,2))
plot(fx)

## linear model for comparison
fx = lm(armc ~ age + weight, data = data.train)
summary(fx)

CV[8,] = c(8, mean((data.valid$armc - predict(fx, newdata = data.valid))^2))


## compare CV
ggplot(CV, aes(x = x, y = CV)) + geom_point() + geom_line() + labs(x = "") + 
  scale_x_continuous(breaks = 1:8, labels = c("Obs Mean", "SLR", "Poly", "Spline", "P-Spline", "Kernel", "Smooth", "MLR")) + 
  theme_bw()


```


## Other materials

* We didn't discuss cross validation, another popular approach, but you can read up on it [here](https://drsimonj.svbtle.com/k-fold-cross-validation-with-modelr-and-broom) and [here](http://rpubs.com/dgrtwo/cv-modelr)

The code that I produced working examples in lecture is [here](https://github.com/P8105/linear_models).
