---
title: "Cross Validation"
output:
  html_document: 
    toc: true
    toc_float: true
---

Although hypothesis tests provide a way to compare nested linear models, in many situations the approaches under consideration don't fit nicely in this paradigm. Indeed, for many modern tools and in many applications, the emphasis lies on prediction accuracy rather than on statistical significance. In these cases, cross validation provides a way to compare the predictive performance of competing methods.

This is the second module in the [Linear Models](topic_iteration.html) topic; the relevant slack channel is [here](https://p8105-fall2018.slack.com/messages/CCAAE9AAU).

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

library(tidyverse)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```

## Some slides

<script async class="speakerdeck-embed" data-id="285289b17d194a4282d53f1800d37199" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>
<div style="margin-bottom:5px"> <strong> <a href="https://speakerdeck.com/jeffgoldsmith/p8105-cross-validation" title="Cross validation" target="_blank">Cross validation</a> </strong> from <strong><a href="https://speakerdeck.com/jeffgoldsmith" target="_blank">Jeff Goldsmith</a></strong>. </div><br>


## Example

I'll write code for today's content in a new R Markdown document called `simulation.Rmd` in the `iteration` directory / repo. The code chunk below loads the usual packages (plus `mgcv`) and sets a seed for reproducibility.

```{r}
library(tidyverse)
library(modelr)
library(mgcv)

set.seed(1)
```


### CV "by hand"

Start with a simulated example. Going to show a nonlinear model, because "complexity" is easier for me to interpret in a case where I can see it. 

```{r}
nonlin_df = tibble(
  id = 1:100,
  x = runif(100, 0, 1),
  y = 1 - 10 * (x - .3) ^ 2 + rnorm(100, 0, .3)
)

ggplot(nonlin_df, aes(x = x, y = y)) + geom_point() + theme_bw()
```

Split into training and testing (we get to use `anti_join`!).

```{r}
train_df = sample_n(nonlin_df, 80)
test_df = anti_join(nonlin_df, train_df, by = "id")

ggplot(train_df, aes(x = x, y = y)) + 
  geom_point() + 
  geom_point(data = test_df, color = "red")
```

Fit three models to the training data. I'm using `mgcv::gam` which fits "additive models." For today, you don't have to know what this means or how it works -- we're putting smooth lines through data clouds, and we can control how smooth we want that to be. 

These aren't nested, so we can't compare using statistical tests

```{r}
lin_mod = lm(y ~ x, data = train_df)
nonlin_mod = mgcv::gam(y ~ s(x), data = train_df)
wiggly_mod = mgcv::gam(y ~ s(x, k = 30), sp = 10e-6, data = train_df)
```

To understand, let's see some fits.

```{r}
train_df %>% 
  add_predictions(nonlin_mod) %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + 
  geom_line(aes(y = pred), color = "red")

train_df %>% 
  add_predictions(wiggly_mod) %>% 
  ggplot(aes(x = x, y = y)) + geom_point() + 
  geom_line(aes(y = pred), color = "red")
```

I can also use `gather_predictions`, which is handy

```{r}
train_df %>% 
  gather_predictions(lin_mod, nonlin_mod, wiggly_mod) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_point() + 
  geom_line(aes(y = pred), color = "red") + 
  facet_wrap(~model)
```

Now I'll compute RMSEs for each

```{r}
rmse(lin_mod, test_df)
rmse(nonlin_mod, test_df)
rmse(wiggly_mod, test_df)
```

This is suggestive that both nonlinear models work better than the linear model, but not conclusive about the smooth and wiggly fits. 

For that, we'll need to iterate. Could be done using loops, but that's a hassle ...


### CV using `modelr`

Luckily, `modelr` has some tools to automate the CV process. In particular `crossv_mc` repeats a training / testing split; datasets are stored using list columns. 

```{r}
cv_df = 
  crossv_mc(nonlin_df, 100) 

cv_df %>% pull(train) %>% .[[1]] %>% as_tibble
cv_df %>% pull(test) %>% .[[1]] %>% as_tibble
```

`crossv_mc` tries to be smart about memory -- rather than repeating the dataset a bunch of times, it saves the data once and stores the indexes for each training / testing split using a `resample` object. This can be coerced to a dataframe (as above) and can often be treated exactly like a dataframe. However, it's not compatible with `gam`, so we have to mess all that up using the code below (if all you want to fit uses `lm`, you can skip this).

```{r}
cv_df =
  cv_df %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))
```

Now I'll fit models and get RMSEs using mutate / map

```{r}
cv_df = 
  cv_df %>% 
  mutate(lin_mod = map(train, ~lm(y ~ x, data = .x)),
         nonlin_mod = map(train, ~mgcv::gam(y ~ s(x), data = .x)),
         wiggly_mod = map(train, ~gam(y ~ s(x, k = 30), sp = 10e-6, data = .x))) %>% 
  mutate(rmse_lin    = map2_dbl(lin_mod, test, ~rmse(model = .x, data = .y)),
         rmse_nonlin = map2_dbl(nonlin_mod, test, ~rmse(model = .x, data = .y)),
         rmse_wiggly = map2_dbl(wiggly_mod, test, ~rmse(model = .x, data = .y)))
```

Last step is plotting the results.

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

Repeating the split helps! Get a sense of variance in prediction error and compare distributions across methods. Smooth fit wins. 

No p-values, though.

### Example: Child Growth

Child growth ...

Import data (available [here](./data/nepalese_children.csv)).
```{r}
child_growth = read_csv("./data/nepalese_children.csv")
```

Quick data plot

```{r}
child_growth %>% 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = .5)
```

Add a "spline term" to allow piecewise linear fits. There's a lot that goes into this that we won't talk about, but these are pretty good models. 

```{r}
child_growth =
  child_growth %>% 
  mutate(weight_sp = (weight > 7) * (weight - 7))
```

Fit three (non-nested) models

```{r}
lin_mod = lm(armc ~ weight, data = child_growth)
pwl_mod = lm(armc ~ weight + weight_sp, data = child_growth)
nonlin_mod = gam(armc ~ s(weight), data = child_growth)
```

Plot three models

```{r}
child_growth %>% 
  gather_predictions(lin_mod, pwl_mod, nonlin_mod) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red") + 
  facet_grid(~model)
```

Not clear which is best! Better check prediction errors...

```{r}
cv_df =
  crossv_mc(child_growth, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))
```


```{r}
cv_df = 
  cv_df %>% 
  mutate(lin_mod = map(train, ~lm(armc ~ weight, data = .x)),
         pwl_mod = map(train, ~lm(armc ~ weight + weight_sp, data = .x)),
         nonlin_mod = map(train, ~gam(armc ~ s(weight), data = as_tibble(.x)))) %>% 
  mutate(rmse_lin    = map2_dbl(lin_mod, test, ~rmse(model = .x, data = .y)),
         rmse_pwl = map2_dbl(pwl_mod, test, ~rmse(model = .x, data = .y)),
         rmse_nonlin = map2_dbl(nonlin_mod, test, ~rmse(model = .x, data = .y)))
```


```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

Based on these splits, nonlin might be a bit better than PWL. I'd probably accept that and use the PWL model for ease of interpretation (and also look at like 1000 runs).


## Other materials

Cross validation is important, but still a bit new to the tidyverse. Some helpful posts are available, though, including:

* This [post](https://drsimonj.svbtle.com/k-fold-cross-validation-with-modelr-and-broom) has a pretty detailed analysis of K fold CV
* [This](http://rpubs.com/dgrtwo/cv-modelr) is a shorter, somewhat more dated example

The Introduction to Statistical Learning with R isn't free online, but if you can track it down Chapter 5 has some useful material as well.

The code that I produced working examples in lecture is [here](https://github.com/P8105/linear_models).
